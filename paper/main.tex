% !TEX program = pdflatex
\documentclass{article}
\usepackage{arxiv}

% ------- Encoding / language -------
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage[T2A]{fontenc} % Для корректной кириллицы в pdfLaTeX

% ------- Math / figures / tables -------
\usepackage{amsmath,amssymb,mathtools}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{detect-all, table-number-alignment=center}
\usepackage{subcaption}
\usepackage{longtable}

% ------- Citations / links -------
\usepackage{natbib}
\usepackage{doi}
\usepackage{url}

% ------- Title / metadata -------
\title{Сравнение современных методов глубокого обучения\\
для автоматической детекции белух в естественной среде}

\author{
  Булкин Антон Павлович \\
	Московский государственный университет имени М. В. Ломоносова \\
        Научный руководитель: Кравцова Ольга Анатольевна \\
 \texttt{bulkin261@gmail.com} \\
  % TODO: Ваша аффилиация
  % Пример:
  % Кафедра \dots, Университет \dots \\
  % Город, Страна \\
  \texttt{<email@domain>} % TODO: ваша почта или удалите строку
}

\date{2025} % при необходимости можно оставить пустым: \date{}

\renewcommand{\shorttitle}{Детекция белух: сравнение современных методов}

% PDF metadata
\hypersetup{
  pdftitle   = {Сравнение современных методов глубокого обучения для автоматической детекции белух в естественной среде},
  pdfauthor  = {Булкин Антон Павлович},
  pdfsubject = {Computer Vision, Object Detection, Wildlife Monitoring},
  pdfkeywords= {детекция объектов, глубокое обучение, белуха, дроны, спутниковые снимки, трекинг, semi-automatic labeling},
  colorlinks = true,
  linkcolor  = {teal!60!black},
  citecolor  = {teal!60!black},
  urlcolor   = {blue!60!black}
}

\begin{document}
\maketitle

\begin{abstract}
В работе исследуются современные архитектуры глубокого обучения для автоматического мониторинга белух — редкого и охраняемого вида, требующего внимательного и регулярного наблюдения. Цель исследования — повысить эффективность мониторинга животных, минимизируя затраты времени и ресурсов на ручную обработку данных, а также создать систему отслеживания взаимодействия животных между собой в рамках одного видеофайла. Предложен комплексный подход: классические решения CV, полуавтоматическая разметка видеоматериалов, обучение и сравнение современных детекторов и трекеров, а также анализ их точности и скорости.
\end{abstract}

\keywords{детекция объектов \and глубокое обучение \and белуха \and дроны \and спутниковые снимки \and трекинг \and полуавтоматическая разметка}

\section{Введение}
Белуха — редкий и охраняемый вид морских млекопитающих, для которого необходимы регулярные и объективные наблюдения в естественной среде обитания. Традиционные подходы — полевые экспедиции, акустический мониторинг, визуальный подсчёт — трудоёмки, подвержены субъективности и ограничены по пространственному и временно́му охвату. Автоматизация на основе методов компьютерного зрения и глубокого обучения позволяет снизить затраты, повысить воспроизводимость и масштабировать мониторинг.

Задача детекции морских млекопитающих в изображениях и видео обычно решается локализацией объектов с ограничивающими рамками и последующим трекингом. Ранние работы использовали классические техники и первые версии одноэтапных и двухэтапных детекторов, показывая базовую применимость, но чувствительность к условиям съёмки и фоновым помехам. Для видео широко применялись связки «детектор + трекер», повышающие устойчивость за счёт межкадровой ассоциации. Современные одноэтапные архитектуры семейства YOLO существенно улучшили соотношение точности и скорости и пригодны для сценариев реального времени. Трансформерные детекторы упрощают инференс, снимая необходимость в постобработке наподобие подавления немаксимумов, и повышают согласованность предсказаний на сложном фоне. Отдельное направление посвящено снижению стоимости аннотирования за счёт полуавтоматической разметки и стратегий активного обучения.

Ключевые трудности домена — малый видимый размер животных в кадре, блики и рябь воды, частичные окклюзии и близость визуально похожих фоновых объектов (лодки, буи, скалы, водоросли). Существенны доменный сдвиг между локациями и условиями съёмки и дисбаланс классов в многоклассовых сценариях. Высокая стоимость ручной аннотации приводит к ограниченным наборам и ошибкам разметки, что снижает переносимость моделей. Наконец, несогласованные протоколы оценки в литературе — разные наборы данных, пороги пересечения, препроцессинг — затрудняют прямое сравнение результатов и выбор решений для практики.

В работе предлагается воспроизводимый бенчмарк детекции белух в реальной морской среде с унифицированным протоколом обучения и оценки. Подготовлены и сопоставлены наборы изображений разного масштаба — 400, 800, 1200 и около 8000 кадров, — где расширение корпуса достигается полуавтоматической разметкой: начальное обучение модели-помощника, автоматическая аннотация неразмеченных кадров и ручная валидация. Рассматриваются одноклассовая и многоклассовая разметки, что позволяет учитывать типичные фоновые объекты на воде.

\section{Обзор литературы / Related works}
Исследования, посвящённые автоматическому мониторингу белух и других морских млекопитающих, активно развиваются в последние годы и охватывают как аэровидеосъёмку, так и анализ спутниковых данных.
Одной из существенных современных работ является статья Alsaidi~\textit{et~al.}~\cite{alsaidi2024beluga_tracking}, где предложена система детекции и трекинга белух на аэровидео с использованием YOLOv7 и алгоритма DeepSORT. Модель показала высокую точность и полноту, а также устойчивость трекинга после постобработки. Аналогичные идеи развиваются в работе Harasyn~\textit{et~al.}~\cite{harasyn2022drone_beluga}, где YOLOv4 и DeepSORT применялись для детекции белух, каяков и лодок в видеопотоках с дронов; достигнута точность около 74\% и полнота 72\%.
Lee~\textit{et~al.}~\cite{lee2021beluga_retinanet} исследовали RetinaNet и Faster~R-CNN на данных залива Камберленд, отметив, что использование тайлинга крупных изображений существенно повышает точность и уменьшает количество ложных срабатываний.

Особое внимание уделяется построению и масштабированию наборов данных.
Araújo~\textit{et~al.}~\cite{araujo2022beluga_sensors} представили датасет \textit{Beluga-5k} с более чем 5500 фотографиями белух и предложили полуавтоматическую разметку. Лучшая модель (YOLOv3-tiny) достигла 97{,}05\%~mAP@0.5, корректно обнаруживая белух даже в условиях сложного фона.
Boulent~\textit{et~al.}~\cite{boulent2023humanloop} предложили интерактивную схему «человек в контуре», при которой нейросеть, обученная на 100 изображениях, достигла 91\% совпадения с экспертами и позволила ускорить аннотацию более чем в пять раз.
Cubaynes и Fretwell~\cite{cubaynes2022whales_dataset} опубликовали набор спутниковых изображений \textit{Whales from Space}, включающий сотни размеченных примеров китов, что обеспечило возможность обучения моделей на данных высокого разрешения.

Использование спутниковых снимков для мониторинга млекопитающих подтверждается рядом работ.
Green~\textit{et~al.}~\cite{green2023gray} применили YOLOv5 для обнаружения серых китов на спутниковых снимках и достигли точности 80–94\% при полноте 84–89\%.
Guirado~\textit{et~al.}~\cite{guirado2019whale_count} предложили каскадный подход, объединяющий классификацию наличия китов и подсчёт особей, что увеличило общую точность на 36\% по сравнению с одноэтапными методами.
Borowicz~\textit{et~al.}~\cite{borowicz2019aerial} показали, что CNN, обученные на аэрофотоснимках, могут быть перенесены на спутниковые данные без значительной потери качества.

В области общих архитектур объектной детекции значительную роль сыграли двухэтапные модели (Faster~R-CNN~\cite{ren2015fasterrcnn}), обеспечившие высокую точность за счёт сети предложений регионов.
Одноэтапные детекторы, начиная с YOLO~\cite{redmon2016yolo} и YOLO9000~\cite{redmon2017yolo9000}, позволили объединить локализацию и классификацию в одном прогоне сети, достигнув 45–60~FPS.
RetinaNet~\cite{lin2017focal} с функцией Focal~Loss улучшил устойчивость к дисбалансу классов и повысил точность при сохранении скорости.
Последующие версии YOLO (в частности, YOLOv7~\cite{wang2022yolov7}) установили новый стандарт по соотношению точности и производительности.

Трансформерные подходы (DETR~\cite{carion2020end}, RT-DETR~\cite{zhao2023rtdetr}) позволили отказаться от постобработки (NMS) и выполнять end-to-end детекцию. RT-DETR показал сопоставимую с YOLO точность при сохранении real-time скорости, что делает его перспективным для видеоаналитики.
Модели открытого словаря (ViLD~\cite{gu2021vild}, GLIP~\cite{li2022glip}, YOLO-World~\cite{cheng2024yoloworld}) расширили возможности детекции на неизвестные классы, включая морские объекты, что особенно важно для практических систем, где структура сцены заранее не фиксирована.

Обзор Tuia~\textit{et~al.}~\cite{tuia2022wildlife} подчёркивает важность машинного обучения для экологического мониторинга. Авторы указывают, что интеграция глубоких моделей с полевыми данными и дроновыми системами позволяет существенно сократить стоимость и повысить масштабируемость наблюдений.
Совокупно, эти исследования формируют основу для разработки универсального бенчмарка детекции белух и показывают актуальность сопоставления современных архитектур на единых данных и метриках.

\bibliographystyle{unsrtnat}
\bibliography{refs} % ваш .bib файл

\end{document}
