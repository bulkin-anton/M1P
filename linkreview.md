| Название | Год | Автор | Ссылка | Краткое содержание |
| --- | --- | --- | --- | --- |
| **Localization and tracking of beluga whales in aerial video using deep learning** | 2024 | Alsaidi M. *et al.* | [Frontiers (DOI:10.3389/fmars.2024.1445698)](https://doi.org/10.3389/fmars.2024.1445698) | В этой работе предлагается система автоматического обнаружения и отслеживания белух на аэросъёмке с помощью модели YOLOv7. Обученный детектор показал высокую точность (~92%) и полноту (~89–94%) при нахождении взрослых особей и детёнышей белух. Для многокомпонентного трекинга применялся алгоритм Deep SORT, но из-за смены идентичности его исходная эффективность была низкой (MOTA 27–48%), которую удалось повысить до ~70% с помощью специальной постобработки. Предложенная система существенно автоматизирует анализ видеоданных дронов, точно обнаруживая и сопровождая белух в естественной среде. |
| **Machine-Learning Approach for Automatic Detection of Wild Beluga Whales from Hand-Held Camera Pictures** | 2022 | Araújo V. *et al.* | [Sensors (MDPI)](https://doi.org/10.3390/s22114107) | Статья предлагает новый метод автоматической детекции белух на фотографиях, основанный на применении свёрточных сетей. Авторы создали датасет *Beluga-5k* (>5,5 тыс. изображений) и полуавтоматическую стратегию разметки, после чего протестировали Mask R-CNN, SSD и YOLOv3-tiny. Лучшая модель (YOLOv3-tiny), дообученная на размеченных данных, достигла 97,05% mAP@0.5 и смогла обнаружить 688 из 706 белух на групповых снимках. Подход обеспечивает высокоточное обнаружение как одиночных, так и скопленных белух даже при шуме на изображениях. |
| **Beluga Whale Detection from Satellite Imagery with Point Labels** | 2025 | Zheng Y. *et al.* | [arXiv:2505.12066](https://arxiv.org/abs/2505.12066) | Разработан конвейер для обнаружения белух и тюленей на спутниковых снимках с использованием точечных аннотаций и модели Segment Anything. После преобразования точек в маски обучался детектор YOLOv8, выделяя три класса: уверенные белухи, неуверенные белухи и тюлени. YOLOv8, обученный по таким данным, достиг F1 ~72,2% для белух и ~70,3% для тюленей, превосходя традиционную разметку в сложных сценах. Подход снижает трудозатраты и улучшает полноту детекции неоднозначных объектов. |
| **Scaling whale monitoring using deep learning: A human-in-the-loop solution for analyzing aerial datasets** | 2023 | Boulent J. *et al.* | [Frontiers (DOI:10.3389/fmars.2023.1099479)](https://doi.org/10.3389/fmars.2023.1099479) | Авторы предложили интерактивный подход «человек в контуре» для анализа аэрофотосъёмки белух. Нейросеть, обученная на 100 изображениях, достигла 91,4% совпадения с экспертами (выше, чем межэкспертное согласие ~88,6%). Применение к полному набору (5334 снимка) дало 4298 белух против 4572 у экспертов. Подход показал, что сочетание ИИ и человека ускоряет и улучшает масштабируемость мониторинга белух. |
| **Detection and tracking of belugas, kayaks and motorized boats in drone video using deep learning** | 2022 | Harasyn M. *et al.* | [J. Unmanned Veh. Systems](https://doi.org/10.1139/juvs-2021-0024) | Работа демонстрирует использование YOLOv4 для обнаружения белух, каяков и лодок на видеосъёмке дронов. Для белух точность составила ~74%, полнота ~72%. Для трекинга применялся DeepSORT, показавший MOTA 37–88% и MOTP 63–86%. Подход ускоряет обработку больших объёмов данных и снижает зависимость от субъективной ручной разметки. |
| **Beluga whale detection in the Cumberland Sound Bay using convolutional neural networks** | 2021 | Lee P.Q. *et al.* | [Can. J. Remote Sensing](https://doi.org/10.1080/07038992.2021.1901221) | Исследование применения RetinaNet и Faster R-CNN для детекции белух в заливе Камберленд. Для повышения точности использовался метод нарезки снимков на тайлы. Без тайлов mAP был низким (0,06), с тайлами RetinaNet достиг 0,20, а Faster R-CNN — 0,28. Faster R-CNN с тайлинговым подходом смог без ложных срабатываний найти всех белух на тесте. |
| **Aerial-trained deep learning networks for surveying cetaceans from satellite imagery** | 2019 | Borowicz A. *et al.* | [PLOS One](https://doi.org/10.1371/journal.pone.0212532) | Показана возможность поиска китов на спутниковых снимках с помощью CNN, обученной на аэрофотоданных. Модель достигла >90% точности в выявлении крупных китообразных на снимках высокого разрешения. Подход позволил автоматизировать обзор обширных акваторий и заложил основу для последующих исследований в этой области. |
| **Whale counting in satellite and aerial images with deep learning** | 2019 | Guirado E. *et al.* | [Sci. Reports](https://doi.org/10.1038/s41598-019-50795-9) | Предложен каскадный метод: сначала CNN обнаруживает китов, затем отдельная модель оценивает их число. Такой подход повысил точность учёта на ~36% по сравнению с одностадийным методом. Результаты показали, что двухэтапная стратегия улучшает надёжность автоматического подсчёта животных. |
| **Gray whale detection in satellite imagery using deep learning** | 2023 | Green K.M. *et al.* | [Remote Sens. Ecol. Conserv.](https://doi.org/10.1002/rse2.352) | YOLOv5 использовался для обнаружения серых китов на спутниковых снимках. Точность достигала 80–94%, полнота 84–89% в различных сценах. Подход подтвердил эффективность современных детекторов (YOLO) для мониторинга животных из космоса. |
| **YOLO-World: Real-Time Open-Vocabulary Object Detection** | 2024 | Cheng T. *et al.* | [arXiv:2401.17270](https://arxiv.org/abs/2401.17270) | YOLO-World объединяет детекцию и языковые модели для *open-vocabulary* распознавания. Введён модуль RepVL-PAN и новая loss-функция region-text. На LVIS модель достигла 35,4 AP при 52 FPS, превысив конкурентов по скорости и точности. |
| **DETRs Beat YOLOs on Real-time Object Detection (RT-DETR)** | 2023 | Zhao Y. *et al.* | [arXiv:2304.08069](https://arxiv.org/abs/2304.08069) | RT-DETR – первый трансформерный детектор, работающий в реальном времени end-to-end. Использует гибридный энкодер и отбор запросов, что улучшает точность. На COCO достиг ~53–54% AP при скорости ~100 FPS, превосходя YOLO по совокупности метрик. |
| **Focal Loss for Dense Object Detection (RetinaNet)** | 2017 | Lin T.-Y. *et al.* | [arXiv:1708.02002](https://arxiv.org/abs/1708.02002) | Предложена функция Focal Loss для борьбы с дисбалансом классов. Она уменьшает вес лёгких примеров и фокусируется на сложных. RetinaNet показал высокую точность при скорости, сравнимой с лёгкими моделями, превзойдя двухэтапные детекторы. |
| **YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors** | 2022 | Wang C.-Y. *et al.* | [arXiv:2207.02696](https://arxiv.org/abs/2207.02696) | YOLOv7 установил новый стандарт по точности и скорости среди детекторов. На COCO достиг 56,8% AP при ≥30 FPS, превысив как CNN-, так и трансформерные модели. Отличается тем, что обучается только на COCO без внешних данных. |
| **Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation (ViLD)** | 2022 | Gu X. *et al.* | [ICLR 2022](https://openaccess.thecvf.com/content/CVPR2021/html/Gu_Open-Vocabulary_Object_Detection_via_Vision-and-Language_Knowledge_Distillation_CVPR_2021_paper.html) | ViLD использует дистилляцию знаний CLIP для передачи возможностей open-vocabulary детектору. Детектор обучается в пространстве совместных признаков изображений и текста, что позволяет распознавать новые классы. На LVIS показал высокую эффективность. |
| **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks** | 2015 | Ren S. *et al.* | [NeurIPS 2015](https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks) | Faster R-CNN ввёл Region Proposal Network, встроенную в CNN. Это ускорило детекцию без падения точности. Подход стал основой для последующих улучшений двухэтапных детекторов. |
| **You Only Look Once: Unified, Real-Time Object Detection (YOLO)** | 2016 | Redmon J. *et al.* | [CVPR 2016](https://doi.org/10.1109/CVPR.2016.91) | YOLO – первая единая одноэтапная архитектура, выполняющая локализацию и классификацию за один прогон сети. Достигала ~45 FPS. Несмотря на уступки по точности двухэтапным методам, YOLO доказала возможность унификации задачи. |
| **YOLO9000: Better, Faster, Stronger** | 2017 | Redmon J., Farhadi A. | [CVPR 2017](https://doi.org/10.1109/CVPR.2017.690) | YOLO9000 (YOLOv2) обучается совместно на COCO и ImageNet через WordTree. Модель может распознавать до 9000 классов в реальном времени, превосходя первую версию YOLO по точности и скорости. |
| **End-to-End Object Detection with Transformers (DETR)** | 2020 | Carion N. *et al.* | [ECCV 2020](https://doi.org/10.1007/978-3-030-58452-8_13) | DETR применяет трансформеры для прямого предсказания ограниченного набора объектов. Исключает NMS и ручные регионы интереса. Несмотря на высокую вычислительную сложность, работа стала основой целого семейства трансформерных детекторов. |
| **Grounded Language-Image Pre-training (GLIP)** | 2022 | Li L.H. *et al.* | [CVPR 2022](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html) | GLIP обучается находить объекты по текстовым описаниям. Использует изображения с богатой аннотацией для обучения визуально-языковой модели. Модель способна к open-vocabulary детекции и поиску объектов по описаниям. |
| **Perspectives in machine learning for wildlife conservation** | 2022 | Tuia D. *et al.* | [Nature Commun.](https://doi.org/10.1038/s41467-022-27980-y) | Обзор применения ML в мониторинге дикой природы. Рассматриваются примеры MegaDetector и дронов для обнаружения животных. Отмечены успехи и проблемы (например, переносимость моделей). Подчёркнута важность интеграции биологии и ИИ. |
